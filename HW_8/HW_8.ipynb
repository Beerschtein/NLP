{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ДЗ_8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выяснить какая архитектура больше подходит для задачи сентимент анализа на данных - CNN или RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*1. Построить свёрточную архитектуру*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2. Построить различные архитектуры с RNN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*3. Построить совместные архитектуры CNN -> RNN и/или (RNN -> CNN)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*4. Сделать выводы что получилось лучше*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Загрузим необходимые библиотеки и скачаем данные.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 21:10:53.232665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking, MaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./train.csv\")\n",
    "df_test = pd.read_csv(\"./test.csv\")\n",
    "df_val = pd.read_csv(\"./val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>204150</td>\n",
       "      <td>Тектоника и рельеф-самое ужасное в мире мучение(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204151</td>\n",
       "      <td>Ходили запускать шар желаний, но у нас не полу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204152</td>\n",
       "      <td>Хочу лето только ради того, что бы направить н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204153</td>\n",
       "      <td>RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204154</td>\n",
       "      <td>RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text\n",
       "0  204150   Тектоника и рельеф-самое ужасное в мире мучение(\n",
       "1  204151  Ходили запускать шар желаний, но у нас не полу...\n",
       "2  204152  Хочу лето только ради того, что бы направить н...\n",
       "3  204153  RT @RonyLiss: @colf_ne блин((\\nа я шипперила Ф...\n",
       "4  204154  RT @anna_romt: @ZADROT_PO_IGRAM блин,каждое во..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181467</td>\n",
       "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181468</td>\n",
       "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181469</td>\n",
       "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181470</td>\n",
       "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181471</td>\n",
       "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  class\n",
       "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
       "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
       "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
       "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
       "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 181467/181467 [03:23<00:00, 889.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 22683/22683 [00:30<00:00, 751.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 22684/22684 [00:30<00:00, 741.22it/s]\n"
     ]
    }
   ],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df_train['text'] = df_train['text'].progress_apply(preprocess_text)\n",
    "df_val['text'] = df_val['text'].progress_apply(preprocess_text)\n",
    "df_test['text'] = df_test['text'].progress_apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_corpus_train = df_train['text'].values\n",
    "text_corpus_valid = df_val['text'].values\n",
    "text_corpus_test = df_test['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=None, \n",
    "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
    "                     lower = False, split = ' ')\n",
    "tokenizer.fit_on_texts(text_corpus_train)\n",
    "\n",
    "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
    "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
    "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
    "\n",
    "word_count = len(tokenizer.index_word) + 1\n",
    "training_length = max([len(i.split()) for i in text_corpus_train])\n",
    "\n",
    "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
    "X_valid = pad_sequences(sequences_val, maxlen=training_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258107"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66107, 66108, 4712, 582, 3, 596],\n",
       " [1, 28151, 214, 6915, 451, 173, 9, 39004],\n",
       " [1, 1467, 1875, 654, 571, 1],\n",
       " [1, 66109, 41, 5700, 39005, 28152, 11483],\n",
       " [66110, 18433, 66111, 66112, 148, 362],\n",
       " [12632, 36, 123, 5, 24],\n",
       " [1, 66113, 15886, 7619, 22180, 67, 2150, 95, 3481, 27, 2150, 12633, 856],\n",
       " [169, 368, 3002, 66114, 3644, 113, 22181, 66115],\n",
       " [66116, 8571, 1185, 89],\n",
       " [12634, 4713, 2689, 39006]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(258108, 27)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count, training_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['class'].values\n",
    "y_val = df_val['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Чтобы определить какая их архитектур нейронных сетей лучше справляется с поставленной задачей, построим несложную CNN-сеть и на ее основе проведем эксперименты - будем добавлять слои с другими сетями, при этом оставляя параметры сетей максимально похожими. Чтобы происходило соревнование алгоритмов.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 27, 30)            7743240   \n",
      "                                                                 \n",
      " masking (Masking)           (None, 27, 30)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 25, 128)           11648     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 25, 128)           0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 25, 128)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 23, 64)            24640     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 64)            0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 23, 64)            0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 64)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                650       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 21:15:49.443150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,780,189\n",
      "Trainable params: 7,780,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv1D(64, 3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 83s 257ms/step - loss: 0.6927 - accuracy: 0.5342 - f1_score: 0.6734 - val_loss: 0.6925 - val_accuracy: 0.5203 - val_f1_score: 0.6710\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 290s 908ms/step - loss: 0.6916 - accuracy: 0.5510 - f1_score: 0.6734 - val_loss: 0.6917 - val_accuracy: 0.5274 - val_f1_score: 0.6710\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 44s 138ms/step - loss: 0.6905 - accuracy: 0.5592 - f1_score: 0.6734 - val_loss: 0.6909 - val_accuracy: 0.5357 - val_f1_score: 0.6710\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 45s 141ms/step - loss: 0.6891 - accuracy: 0.5675 - f1_score: 0.6734 - val_loss: 0.6897 - val_accuracy: 0.5451 - val_f1_score: 0.6710\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 56s 177ms/step - loss: 0.6870 - accuracy: 0.5782 - f1_score: 0.6734 - val_loss: 0.6880 - val_accuracy: 0.5513 - val_f1_score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3) \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 8ms/step - loss: 0.6894 - accuracy: 0.5412 - f1_score: 0.6709\n",
      "\n",
      "\n",
      "Test score: 0.6893725991249084\n",
      "Test accuracy: 0.5411982536315918\n"
     ]
    }
   ],
   "source": [
    "score_cnn = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score_cnn[0])\n",
    "print('Test accuracy:', score_cnn[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 27, 30)            7743240   \n",
      "                                                                 \n",
      " masking_1 (Masking)         (None, 27, 30)            0         \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 128)               20352     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,789,021\n",
      "Trainable params: 7,789,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(SimpleRNN(128))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 43s 129ms/step - loss: 0.6933 - accuracy: 0.4973 - f1_score: 0.6734 - val_loss: 0.6919 - val_accuracy: 0.5139 - val_f1_score: 0.6710\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 43s 135ms/step - loss: 0.6913 - accuracy: 0.5099 - f1_score: 0.6734 - val_loss: 0.6897 - val_accuracy: 0.5391 - val_f1_score: 0.6710\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 46s 145ms/step - loss: 0.6892 - accuracy: 0.5289 - f1_score: 0.6734 - val_loss: 0.6870 - val_accuracy: 0.5508 - val_f1_score: 0.6710\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 51s 161ms/step - loss: 0.6867 - accuracy: 0.5500 - f1_score: 0.6734 - val_loss: 0.6840 - val_accuracy: 0.5611 - val_f1_score: 0.6710\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 53s 166ms/step - loss: 0.6841 - accuracy: 0.5647 - f1_score: 0.6734 - val_loss: 0.6812 - val_accuracy: 0.5686 - val_f1_score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3) \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 1s 21ms/step - loss: 0.6944 - accuracy: 0.5409 - f1_score: 0.6709\n",
      "\n",
      "\n",
      "Test score: 0.6944053769111633\n",
      "Test accuracy: 0.5408896803855896\n"
     ]
    }
   ],
   "source": [
    "score_rnn = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score_rnn[0])\n",
    "print('Test accuracy:', score_rnn[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 27, 30)            7743240   \n",
      "                                                                 \n",
      " masking_2 (Masking)         (None, 27, 30)            0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 128)               61440     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,830,109\n",
      "Trainable params: 7,830,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(GRU(128,recurrent_dropout=0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 142s 437ms/step - loss: 0.6931 - accuracy: 0.5169 - f1_score: 0.6734 - val_loss: 0.6928 - val_accuracy: 0.5422 - val_f1_score: 0.6710\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 291s 910ms/step - loss: 0.6923 - accuracy: 0.5554 - f1_score: 0.6734 - val_loss: 0.6912 - val_accuracy: 0.5715 - val_f1_score: 0.6710\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 77s 240ms/step - loss: 0.6888 - accuracy: 0.5919 - f1_score: 0.6734 - val_loss: 0.6851 - val_accuracy: 0.5984 - val_f1_score: 0.6710\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 240s 755ms/step - loss: 0.6784 - accuracy: 0.6141 - f1_score: 0.6734 - val_loss: 0.6706 - val_accuracy: 0.6119 - val_f1_score: 0.6710\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 131s 410ms/step - loss: 0.6575 - accuracy: 0.6367 - f1_score: 0.6734 - val_loss: 0.6471 - val_accuracy: 0.6339 - val_f1_score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3) \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 54ms/step - loss: 0.6626 - accuracy: 0.6108 - f1_score: 0.6709\n",
      "\n",
      "\n",
      "Test score: 0.6626438498497009\n",
      "Test accuracy: 0.610809862613678\n"
     ]
    }
   ],
   "source": [
    "score_gru = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score_gru[0])\n",
    "print('Test accuracy:', score_gru[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 27, 30)            7743240   \n",
      "                                                                 \n",
      " masking_3 (Masking)         (None, 27, 30)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               81408     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850,077\n",
      "Trainable params: 7,850,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(LSTM(128, recurrent_dropout=0.2))\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 162s 495ms/step - loss: 0.6929 - accuracy: 0.5216 - f1_score: 0.6734 - val_loss: 0.6923 - val_accuracy: 0.5634 - val_f1_score: 0.6710\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 155s 486ms/step - loss: 0.6913 - accuracy: 0.5738 - f1_score: 0.6734 - val_loss: 0.6894 - val_accuracy: 0.5978 - val_f1_score: 0.6710\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 115s 359ms/step - loss: 0.6859 - accuracy: 0.5974 - f1_score: 0.6734 - val_loss: 0.6802 - val_accuracy: 0.6038 - val_f1_score: 0.6710\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 156s 491ms/step - loss: 0.6712 - accuracy: 0.6080 - f1_score: 0.6734 - val_loss: 0.6607 - val_accuracy: 0.6116 - val_f1_score: 0.6710\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 534s 2s/step - loss: 0.6502 - accuracy: 0.6257 - f1_score: 0.6734 - val_loss: 0.6399 - val_accuracy: 0.6412 - val_f1_score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3) \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 2s 48ms/step - loss: 0.6550 - accuracy: 0.6090 - f1_score: 0.6709\n",
      "\n",
      "\n",
      "Test score: 0.6550308465957642\n",
      "Test accuracy: 0.6090023517608643\n"
     ]
    }
   ],
   "source": [
    "score_lstm = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score_lstm[0])\n",
    "print('Test accuracy:', score_lstm[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN > RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 27, 30)            7743240   \n",
      "                                                                 \n",
      " masking_4 (Masking)         (None, 27, 30)            0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 25, 128)           11648     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 25, 128)           0         \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 25, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,809,117\n",
      "Trainable params: 7,809,117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(LSTM(64,recurrent_dropout=0.2))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 69s 208ms/step - loss: 0.6929 - accuracy: 0.5261 - f1_score: 0.6734 - val_loss: 0.6924 - val_accuracy: 0.5639 - val_f1_score: 0.6710\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 70s 219ms/step - loss: 0.6916 - accuracy: 0.5590 - f1_score: 0.6734 - val_loss: 0.6907 - val_accuracy: 0.5750 - val_f1_score: 0.6710\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 78s 245ms/step - loss: 0.6887 - accuracy: 0.5778 - f1_score: 0.6734 - val_loss: 0.6863 - val_accuracy: 0.5868 - val_f1_score: 0.6710\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 77s 241ms/step - loss: 0.6816 - accuracy: 0.5895 - f1_score: 0.6734 - val_loss: 0.6769 - val_accuracy: 0.5903 - val_f1_score: 0.6710\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 85s 268ms/step - loss: 0.6693 - accuracy: 0.6004 - f1_score: 0.6734 - val_loss: 0.6643 - val_accuracy: 0.6028 - val_f1_score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3) \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 3s 63ms/step - loss: 0.6762 - accuracy: 0.5744 - f1_score: 0.6709\n",
      "\n",
      "\n",
      "Test score: 0.6761654615402222\n",
      "Test accuracy: 0.574394941329956\n"
     ]
    }
   ],
   "source": [
    "score_cnn_rnn = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score_cnn_rnn[0])\n",
    "print('Test accuracy:', score_cnn_rnn[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN > CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 27, 30)            7743240   \n",
      "                                                                 \n",
      " masking_5 (Masking)         (None, 27, 30)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 27, 128)           81408     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 25, 128)           49280     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 25, 128)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,875,229\n",
      "Trainable params: 7,875,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=word_count,\n",
    "              input_length=training_length,\n",
    "              output_dim=30,\n",
    "              trainable=True,\n",
    "              mask_zero=True))\n",
    "model.add(Masking(mask_value=0.0))\n",
    "model.add(LSTM(128,recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(Conv1D(128, 3))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319/319 [==============================] - 140s 426ms/step - loss: 0.6926 - accuracy: 0.5073 - f1_score: 0.6734 - val_loss: 0.6924 - val_accuracy: 0.5049 - val_f1_score: 0.6710\n",
      "Epoch 2/5\n",
      "319/319 [==============================] - 141s 442ms/step - loss: 0.6910 - accuracy: 0.5321 - f1_score: 0.6734 - val_loss: 0.6907 - val_accuracy: 0.5231 - val_f1_score: 0.6710\n",
      "Epoch 3/5\n",
      "319/319 [==============================] - 355s 1s/step - loss: 0.6870 - accuracy: 0.5776 - f1_score: 0.6734 - val_loss: 0.6856 - val_accuracy: 0.5676 - val_f1_score: 0.6710\n",
      "Epoch 4/5\n",
      "319/319 [==============================] - 152s 473ms/step - loss: 0.6768 - accuracy: 0.5956 - f1_score: 0.6734 - val_loss: 0.6743 - val_accuracy: 0.6002 - val_f1_score: 0.6710\n",
      "Epoch 5/5\n",
      "319/319 [==============================] - 256s 802ms/step - loss: 0.6635 - accuracy: 0.6036 - f1_score: 0.6734 - val_loss: 0.6646 - val_accuracy: 0.6123 - val_f1_score: 0.6710\n"
     ]
    }
   ],
   "source": [
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3) \n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=512,\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 9s 195ms/step - loss: 0.6748 - accuracy: 0.5781 - f1_score: 0.6709\n",
      "\n",
      "\n",
      "Test score: 0.6747561693191528\n",
      "Test accuracy: 0.5781422257423401\n"
     ]
    }
   ],
   "source": [
    "score_rnn_cnn = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score_rnn_cnn[0])\n",
    "print('Test accuracy:', score_rnn_cnn[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Для удобства выведем результаты в таблицу:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRU</td>\n",
       "      <td>0.610810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.609002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RNN_CNN</td>\n",
       "      <td>0.578142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN_RNN</td>\n",
       "      <td>0.574395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.541198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RNN</td>\n",
       "      <td>0.540890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model  accuracy\n",
       "2      GRU  0.610810\n",
       "3     LSTM  0.609002\n",
       "5  RNN_CNN  0.578142\n",
       "4  CNN_RNN  0.574395\n",
       "0      CNN  0.541198\n",
       "1      RNN  0.540890"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'model': ['CNN', 'RNN', 'GRU', 'LSTM','CNN_RNN', 'RNN_CNN'], \n",
    "                       'accuracy': [score_cnn[1], score_rnn[1], score_gru[1], \n",
    "                                    score_lstm[1], score_cnn_rnn[1], score_rnn_cnn[1]]})\n",
    "result.sort_values(by='accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ВЫВОД: результаты экспермента показывают, что при максимально равных условиях лучше всего справляются с поставленной задачей нейронные сети, способные бороться с \"затуханием/взрывом\" градиента (LSTM, GRU). Обе они лидируют с заметным отрывом и имеют практически одинаковый показатель \"accuracy\". На втором месте - совместные архитектуры (RNN_CNN, CNN_RNN). Они так же имеют очень похожий друг с другом показатель \"accuracy\", что подталкивает к выводу - не важно какой слой следует за каким. Результат получается одинаковым. И, неожиданно, на третьем месте оказались сети CNN и RNN. Их \"accuracy\" тоже практически одинаковый. Однако обычная CNN хоть и на тысячные доли, но обогнала сеть c рекуррентным слоем RNN! Можно только предположить, что набор данных был не очень большого размера и длинны. И затухание ингредиента не имело значимого влияния. В результате простая сеть с простой архитектурой показала чуть лучший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
