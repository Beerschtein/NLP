{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cde3ad8",
   "metadata": {},
   "source": [
    "## ДЗ_7 - Тема “Свёртки”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b49079",
   "metadata": {},
   "source": [
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe2640b",
   "metadata": {},
   "source": [
    "1. Учим conv сеть для классификации\n",
    "2. Рассмотреть 2-а варианта сеточек"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda70f46",
   "metadata": {},
   "source": [
    "2.1 Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6ff4bf",
   "metadata": {},
   "source": [
    "2.2 Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327d247f",
   "metadata": {},
   "source": [
    "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d8957d",
   "metadata": {},
   "source": [
    "### Установим необходимые библиотеки и загрузим даные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9df38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop_words in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (2018.7.23)\r\n",
      "Requirement already satisfied: pymorphy2 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (0.9)\r\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pymorphy2) (2.4.417127.4579844)\r\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pymorphy2) (0.7.2)\r\n",
      "Requirement already satisfied: docopt>=0.6 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pymorphy2) (0.6.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install stop_words pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2bf0760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.18.0-cp38-cp38-macosx_10_14_x86_64.whl (12.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from tensorflow-addons) (21.3)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging->tensorflow-addons) (3.0.9)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.18.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1580f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (4.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/mac/miniconda3/envs/pytorch_p38/lib/python3.8/site-packages (from gensim) (1.20.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5e15b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0835f02b",
   "metadata": {},
   "source": [
    "**Зададим гиперпараметры для обучения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9857802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 80\n",
    "num_classes = 1\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "print_batch_n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2b1507",
   "metadata": {},
   "source": [
    "**Загрузим датасет.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad313a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =  pd.read_excel('отзывы за лето.xls')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785236c",
   "metadata": {},
   "source": [
    "**Удалим столбец Date.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ce24f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39afcc",
   "metadata": {},
   "source": [
    "**Сделаем предобработку текста.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf36960",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18c66f",
   "metadata": {},
   "source": [
    "**Разделим данные на test и train.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c0a8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79c6e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>5</td>\n",
       "      <td>Наконец-то исправили эту чушь с неоргинальной ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>5</td>\n",
       "      <td>Удобно в использовании</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>5</td>\n",
       "      <td>Класс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17941</th>\n",
       "      <td>5</td>\n",
       "      <td>Удобно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content\n",
       "3517        5  Наконец-то исправили эту чушь с неоргинальной ...\n",
       "12399       5                             Удобно в использовании\n",
       "3833        5                                            Отлично\n",
       "13250       5                                              Класс\n",
       "17941       5                                             Удобно"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac5fc3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>5</td>\n",
       "      <td>Всё отлично!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19916</th>\n",
       "      <td>5</td>\n",
       "      <td>Мне нравится. Удобно. Еще ни разу не подвел!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>3</td>\n",
       "      <td>Иногда слишком долго приходится ждать пока зап...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>5</td>\n",
       "      <td>Отличное приложение. Легко отслеживать свои ра...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>5</td>\n",
       "      <td>Все грамотно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content\n",
       "1457        5                                     Всё отлично!!!\n",
       "19916       5       Мне нравится. Удобно. Еще ни разу не подвел!\n",
       "2112        3  Иногда слишком долго приходится ждать пока зап...\n",
       "15154       5  Отличное приложение. Легко отслеживать свои ра...\n",
       "18329       5                                       Все грамотно"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197f02ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Content'] = df_train['Content'].apply(preprocess_text)\n",
    "df_test['Content'] = df_test['Content'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96e7bd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>5</td>\n",
       "      <td>наконецтый исправить чушь снеоргинальный проши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12399</th>\n",
       "      <td>5</td>\n",
       "      <td>удобно использование</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833</th>\n",
       "      <td>5</td>\n",
       "      <td>отлично</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13250</th>\n",
       "      <td>5</td>\n",
       "      <td>класс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17941</th>\n",
       "      <td>5</td>\n",
       "      <td>удобно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content\n",
       "3517        5  наконецтый исправить чушь снеоргинальный проши...\n",
       "12399       5                               удобно использование\n",
       "3833        5                                            отлично\n",
       "13250       5                                              класс\n",
       "17941       5                                             удобно"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99992bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>5</td>\n",
       "      <td>отлично</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19916</th>\n",
       "      <td>5</td>\n",
       "      <td>нравиться удобно разуна подвести</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>3</td>\n",
       "      <td>приходиться ждать запуститься приложение бввае...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>5</td>\n",
       "      <td>отличный приложение легко отслеживать расход о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18329</th>\n",
       "      <td>5</td>\n",
       "      <td>грамотно</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rating                                            Content\n",
       "1457        5                                            отлично\n",
       "19916       5                   нравиться удобно разуна подвести\n",
       "2112        3  приходиться ждать запуститься приложение бввае...\n",
       "15154       5  отличный приложение легко отслеживать расход о...\n",
       "18329       5                                           грамотно"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc5a86a",
   "metadata": {},
   "source": [
    "**Сформируем сорварь. Проиндексируем токены.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf24dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df_train[\"Content\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00822ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(train_corpus)\n",
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6f927",
   "metadata": {},
   "source": [
    "**Выберем наиболее часто встречающиеся токены.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acfb48ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['приложение',\n",
       " 'удобно',\n",
       " 'работать',\n",
       " 'удобный',\n",
       " 'отлично',\n",
       " 'нравиться',\n",
       " 'хороший',\n",
       " 'отличный',\n",
       " 'телефон',\n",
       " 'супер']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]\n",
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f7f4053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "275c867c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76c53175",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"Content\"]], dtype=np.int32)\n",
    "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"Content\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "150c0f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "train_enc_labels = le.fit_transform(df_train['Rating']) \n",
    "test_enc_labels = le.transform(df_test['Rating'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bfd7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "y_train = tf.keras.utils.to_categorical(train_enc_labels, num_classes=num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(test_enc_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc62d531",
   "metadata": {},
   "source": [
    "**Соберем сеть.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93cd550a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 80, 256)           256000    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 78, 256)           196864    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 78, 256)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 40)                10280     \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 40)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                410       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 463,609\n",
      "Trainable params: 463,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=256, input_length=max_len))\n",
    "model.add(Conv1D(256, 3))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(40))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac2a28",
   "metadata": {},
   "source": [
    "**Скомпилируем ее.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "848c1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=num_classes, average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c10883f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 8s 333ms/step - loss: 0.1856 - accuracy: 0.9452 - f1_score: 0.9159 - val_loss: 1.4819 - val_accuracy: 0.7307 - val_f1_score: 0.3826\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 9s 350ms/step - loss: 0.1833 - accuracy: 0.9465 - f1_score: 0.9177 - val_loss: 1.5056 - val_accuracy: 0.7271 - val_f1_score: 0.3804\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 9s 370ms/step - loss: 0.1820 - accuracy: 0.9465 - f1_score: 0.9180 - val_loss: 1.5404 - val_accuracy: 0.7314 - val_f1_score: 0.3744\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 10s 400ms/step - loss: 0.1803 - accuracy: 0.9466 - f1_score: 0.9195 - val_loss: 1.5561 - val_accuracy: 0.7314 - val_f1_score: 0.3774\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 11s 446ms/step - loss: 0.1790 - accuracy: 0.9471 - f1_score: 0.9192 - val_loss: 1.5725 - val_accuracy: 0.7314 - val_f1_score: 0.3840\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 11s 437ms/step - loss: 0.1780 - accuracy: 0.9469 - f1_score: 0.9186 - val_loss: 1.5956 - val_accuracy: 0.7336 - val_f1_score: 0.3885\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 11s 435ms/step - loss: 0.1769 - accuracy: 0.9471 - f1_score: 0.9195 - val_loss: 1.6239 - val_accuracy: 0.7314 - val_f1_score: 0.3796\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 11s 443ms/step - loss: 0.1776 - accuracy: 0.9469 - f1_score: 0.9195 - val_loss: 1.6194 - val_accuracy: 0.7350 - val_f1_score: 0.3864\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 11s 460ms/step - loss: 0.1767 - accuracy: 0.9469 - f1_score: 0.9206 - val_loss: 1.6343 - val_accuracy: 0.7285 - val_f1_score: 0.3875\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 12s 477ms/step - loss: 0.1751 - accuracy: 0.9469 - f1_score: 0.9187 - val_loss: 1.6656 - val_accuracy: 0.7329 - val_f1_score: 0.3856\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 12s 466ms/step - loss: 0.1767 - accuracy: 0.9465 - f1_score: 0.9177 - val_loss: 1.6807 - val_accuracy: 0.7314 - val_f1_score: 0.3803\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 11s 457ms/step - loss: 0.1773 - accuracy: 0.9475 - f1_score: 0.9213 - val_loss: 1.6864 - val_accuracy: 0.7300 - val_f1_score: 0.3692\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.1762 - accuracy: 0.9468 - f1_score: 0.9185 - val_loss: 1.6965 - val_accuracy: 0.7329 - val_f1_score: 0.3824\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 12s 472ms/step - loss: 0.1745 - accuracy: 0.9471 - f1_score: 0.9196 - val_loss: 1.6839 - val_accuracy: 0.7278 - val_f1_score: 0.3796\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 12s 484ms/step - loss: 0.1722 - accuracy: 0.9479 - f1_score: 0.9215 - val_loss: 1.7182 - val_accuracy: 0.7336 - val_f1_score: 0.3856\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 12s 489ms/step - loss: 0.1727 - accuracy: 0.9475 - f1_score: 0.9206 - val_loss: 1.7173 - val_accuracy: 0.7307 - val_f1_score: 0.3823\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 12s 487ms/step - loss: 0.1714 - accuracy: 0.9479 - f1_score: 0.9205 - val_loss: 1.7424 - val_accuracy: 0.7300 - val_f1_score: 0.3933\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 12s 497ms/step - loss: 0.1749 - accuracy: 0.9472 - f1_score: 0.9203 - val_loss: 1.7243 - val_accuracy: 0.7314 - val_f1_score: 0.3857\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 13s 502ms/step - loss: 0.1732 - accuracy: 0.9461 - f1_score: 0.9186 - val_loss: 1.7575 - val_accuracy: 0.7314 - val_f1_score: 0.3872\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 12s 480ms/step - loss: 0.1717 - accuracy: 0.9476 - f1_score: 0.9203 - val_loss: 1.7454 - val_accuracy: 0.7336 - val_f1_score: 0.3888\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss') \n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard])\n",
    "#                     callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "251980dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 91ms/step - loss: 1.6487 - accuracy: 0.7366 - f1_score: 0.3675\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d9392",
   "metadata": {},
   "source": [
    "**Загрузим предобученную сеть.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e6454177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-15 16:29:40--  http://vectors.nlpl.eu/repository/20/220.zip\n",
      "Распознаётся vectors.nlpl.eu (vectors.nlpl.eu)… 129.240.189.181\n",
      "Подключение к vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.181|:80... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 638171816 (609M) [application/zip]\n",
      "Сохранение в: «220.zip.1»\n",
      "\n",
      "220.zip.1           100%[===================>] 608,61M  19,7MB/s    за 34s     \n",
      "\n",
      "2022-11-15 16:30:13 (18,2 MB/s) - «220.zip.1» сохранён [638171816/638171816]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://vectors.nlpl.eu/repository/20/220.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "296a6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  220.zip\n",
      "  inflating: meta.json               \n",
      "  inflating: model.bin               \n",
      "  inflating: model.txt               \n",
      "  inflating: README                  \n"
     ]
    }
   ],
   "source": [
    "!unzip 220.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af4541a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2070a556",
   "metadata": {},
   "source": [
    "**Загрузим векторы из предобученной модели.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e155a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "851ad0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249333"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "395da90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавлено 205707 векторов.\n"
     ]
    }
   ],
   "source": [
    "# embeddings_index = {}\n",
    "# i = 0\n",
    "# ids = []\n",
    "# with open('model.txt') as f:\n",
    "#     for line in f:\n",
    "#       i += 1\n",
    "#       word, coefs = line.split(maxsplit=1)\n",
    "#       coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "#       if i > 1:\n",
    "#         text, sem = word.split('_')\n",
    "#         embeddings_index[text] = coefs\n",
    "#         ids.append(text)\n",
    "\n",
    "\n",
    "# print(f'Добавлено {len(embeddings_index)} векторов.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c6acb77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавлены эмбеддинги для 869 слов (130 слов не найдено).\n"
     ]
    }
   ],
   "source": [
    "# embedding_dim = 300\n",
    "# hits = 0\n",
    "# misses = 0\n",
    "\n",
    "# embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "# for word, i in vocabulary.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None:\n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "#         hits += 1\n",
    "#     else:\n",
    "#         misses += 1\n",
    "\n",
    "# print(f'Добавлены эмбеддинги для {hits} слов ({misses} слов не найдено).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fc7de",
   "metadata": {},
   "source": [
    "**Подгоним веторы по размеру эмбеддингов из предыдущей модели.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae126e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model_matrix = [word_model[i][:256] for i in range(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ff7b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 80, 256)           256000    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 78, 256)           196864    \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 78, 256)           0         \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 256)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 40)                10280     \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 40)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                410       \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 463,609\n",
      "Trainable params: 463,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.keras.initializers.Constant(word_model_matrix)\n",
    "\n",
    "model_w = Sequential()\n",
    "model_w.add(Embedding(input_dim=max_words, output_dim=256, embeddings_initializer =initializer, input_length=max_len))\n",
    "model_w.add(Conv1D(256, 3))\n",
    "model_w.add(Activation(\"relu\"))\n",
    "model_w.add(GlobalMaxPool1D())\n",
    "model_w.add(Dense(40))\n",
    "model_w.add(Activation(\"relu\"))\n",
    "model_w.add(Dense(10))\n",
    "model_w.add(Activation(\"relu\"))\n",
    "model_w.add(Dense(num_classes))\n",
    "model_w.add(Activation('softmax'))\n",
    "model_w.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4bd7da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', tfa.metrics.F1Score(num_classes=num_classes, average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c4dec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25/25 [==============================] - 12s 440ms/step - loss: 0.8512 - accuracy: 0.7437 - f1_score: 0.2912 - val_loss: 0.7613 - val_accuracy: 0.7300 - val_f1_score: 0.3043\n",
      "Epoch 2/20\n",
      "25/25 [==============================] - 11s 460ms/step - loss: 0.6012 - accuracy: 0.7913 - f1_score: 0.3244 - val_loss: 0.7926 - val_accuracy: 0.7415 - val_f1_score: 0.2851\n",
      "Epoch 3/20\n",
      "25/25 [==============================] - 12s 485ms/step - loss: 0.5819 - accuracy: 0.7959 - f1_score: 0.3201 - val_loss: 0.7679 - val_accuracy: 0.7422 - val_f1_score: 0.2883\n",
      "Epoch 4/20\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 0.5746 - accuracy: 0.7981 - f1_score: 0.3270 - val_loss: 0.7649 - val_accuracy: 0.7386 - val_f1_score: 0.2876\n",
      "Epoch 5/20\n",
      "25/25 [==============================] - 13s 523ms/step - loss: 0.5681 - accuracy: 0.7995 - f1_score: 0.3269 - val_loss: 0.7676 - val_accuracy: 0.7430 - val_f1_score: 0.2832\n",
      "Epoch 6/20\n",
      "25/25 [==============================] - 12s 498ms/step - loss: 0.5665 - accuracy: 0.7989 - f1_score: 0.3258 - val_loss: 0.7548 - val_accuracy: 0.7394 - val_f1_score: 0.2840\n",
      "Epoch 7/20\n",
      "25/25 [==============================] - 13s 502ms/step - loss: 0.5669 - accuracy: 0.7995 - f1_score: 0.3270 - val_loss: 0.8114 - val_accuracy: 0.7372 - val_f1_score: 0.2793\n",
      "Epoch 8/20\n",
      "25/25 [==============================] - 13s 506ms/step - loss: 0.5640 - accuracy: 0.7988 - f1_score: 0.3244 - val_loss: 0.7749 - val_accuracy: 0.7372 - val_f1_score: 0.2828\n",
      "Epoch 9/20\n",
      "25/25 [==============================] - 14s 556ms/step - loss: 0.5648 - accuracy: 0.7992 - f1_score: 0.3255 - val_loss: 0.8351 - val_accuracy: 0.7394 - val_f1_score: 0.2823\n",
      "Epoch 10/20\n",
      "25/25 [==============================] - 13s 528ms/step - loss: 0.5664 - accuracy: 0.7983 - f1_score: 0.3205 - val_loss: 0.8000 - val_accuracy: 0.7386 - val_f1_score: 0.2858\n",
      "Epoch 11/20\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 0.5642 - accuracy: 0.7992 - f1_score: 0.3238 - val_loss: 0.7685 - val_accuracy: 0.7379 - val_f1_score: 0.2783\n",
      "Epoch 12/20\n",
      "25/25 [==============================] - 13s 511ms/step - loss: 0.5578 - accuracy: 0.8009 - f1_score: 0.3264 - val_loss: 0.8105 - val_accuracy: 0.7430 - val_f1_score: 0.2935\n",
      "Epoch 13/20\n",
      "25/25 [==============================] - 14s 541ms/step - loss: 0.5558 - accuracy: 0.8003 - f1_score: 0.3248 - val_loss: 0.7635 - val_accuracy: 0.7444 - val_f1_score: 0.2934\n",
      "Epoch 14/20\n",
      "25/25 [==============================] - 13s 518ms/step - loss: 0.5590 - accuracy: 0.7992 - f1_score: 0.3233 - val_loss: 0.7707 - val_accuracy: 0.7451 - val_f1_score: 0.2947\n",
      "Epoch 15/20\n",
      "25/25 [==============================] - 14s 548ms/step - loss: 0.5638 - accuracy: 0.7986 - f1_score: 0.3238 - val_loss: 0.7980 - val_accuracy: 0.7386 - val_f1_score: 0.2853\n",
      "Epoch 16/20\n",
      "25/25 [==============================] - 13s 531ms/step - loss: 0.5551 - accuracy: 0.8003 - f1_score: 0.3239 - val_loss: 0.7851 - val_accuracy: 0.7372 - val_f1_score: 0.2806\n",
      "Epoch 17/20\n",
      "25/25 [==============================] - 14s 563ms/step - loss: 0.5574 - accuracy: 0.8007 - f1_score: 0.3254 - val_loss: 0.8591 - val_accuracy: 0.7379 - val_f1_score: 0.2815\n",
      "Epoch 18/20\n",
      "25/25 [==============================] - 14s 546ms/step - loss: 0.5523 - accuracy: 0.8015 - f1_score: 0.3263 - val_loss: 0.7894 - val_accuracy: 0.7350 - val_f1_score: 0.2795\n",
      "Epoch 19/20\n",
      "25/25 [==============================] - 14s 562ms/step - loss: 0.5501 - accuracy: 0.8013 - f1_score: 0.3253 - val_loss: 0.8110 - val_accuracy: 0.7394 - val_f1_score: 0.2911\n",
      "Epoch 20/20\n",
      "25/25 [==============================] - 15s 596ms/step - loss: 0.5490 - accuracy: 0.8022 - f1_score: 0.3267 - val_loss: 0.8054 - val_accuracy: 0.7336 - val_f1_score: 0.2853\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss') \n",
    "\n",
    "history_w = model_w.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard])\n",
    "#                     callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "276e8125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 93ms/step - loss: 0.7703 - accuracy: 0.7558 - f1_score: 0.2926\n"
     ]
    }
   ],
   "source": [
    "score = model_w.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae6d2bc",
   "metadata": {},
   "source": [
    "### Вывод: обе модели показали примерно одинаковые результаты по показателю accuracy - 0.7366 у модели которая обучалась сама против 0.7558 у предобученной. Однако показатель f1_score у предобученной модели существенно ниже - 0.2926 против 0.3675. Вероятно, это может быть связано с тем, что не для всех слов в нашем датасете нашлись предобученные эмбеддинги. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6608a6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc4649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adfa142",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
